{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: Model to predict Boston housing prices #\n",
    "\n",
    "Dataset - https://archive.ics.uci.edu/ml/datasets/Housing\n",
    "\n",
    "This is a regression problem. The features are as follows:\n",
    "\n",
    "1. CRIM: per capita crime rate by town \n",
    "2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "3. INDUS: proportion of non-retail business acres per town \n",
    "4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "5. NOX: nitric oxides concentration (parts per 10 million) \n",
    "6. RM: average number of rooms per dwelling \n",
    "7. AGE: proportion of owner-occupied units built prior to 1940 \n",
    "8. DIS: weighted distances to five Boston employment centres \n",
    "9. RAD: index of accessibility to radial highways \n",
    "10. TAX: full-value property-tax rate per $10,000 \n",
    "11. PTRATIO: pupil-teacher ratio by town \n",
    "12. B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "13. LSTAT: % lower status of the population \n",
    "\n",
    "The target label is:\n",
    "\n",
    "14. MEDV: Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: NN with extra hidden layers ##\n",
    "\n",
    "We follow the following approach:\n",
    "\n",
    "* ** Perform standardization during the model evaluation process, within each fold of cross validation. This ensures that there is no data leakage from each test set cross validation fold into the training data. **\n",
    "* The NN structure is 13 inputs -> [13 -> 6] -> 1 output\n",
    "* The extra hidden layer allows the model to extract and recombine higher order features embedded in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 103.28 (236.30) MSE\n"
     ]
    }
   ],
   "source": [
    "# Regression Example With Boston Dataset: Standardized and Larger\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load dataset\n",
    "dataframe = pandas.read_csv(\"housing.csv\", delim_whitespace=True, header=None)\n",
    "dataset = dataframe.values\n",
    "\n",
    "# Split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:13]\n",
    "Y = dataset[:,13]\n",
    "\n",
    "# Define the model\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, \n",
    "                    input_dim=13, \n",
    "                    init='normal', \n",
    "                    activation='relu'))\n",
    "    # Extra hidden layer with 6 neurons\n",
    "    model.add(Dense(6, \n",
    "                    init='normal', \n",
    "                    activation='relu'))\n",
    "    model.add(Dense(1, \n",
    "                    init='normal'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', \n",
    "                   KerasRegressor(build_fn=larger_model, \n",
    "                                  nb_epoch=50, \n",
    "                                  batch_size=5, \n",
    "                                  verbose=0)))\n",
    "\n",
    "# Set up pipeline\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "# \n",
    "kfold = KFold(n_splits=10, \n",
    "              random_state=seed)\n",
    "\n",
    "# Cross validation scores\n",
    "results = cross_val_score(pipeline, \n",
    "                          X, \n",
    "                          Y, \n",
    "                          cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: NN with a wider network topology ##\n",
    "\n",
    "* We keep a shallow network architecture(1 hidden layer) but we double the number of neurons in the hidden layer(20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: 22.77 (24.89) MSE\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "NN structure: 13 inputs -> [20] -> 1 output\n",
    "'''\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, \n",
    "                    input_dim=13, \n",
    "                    init='normal', \n",
    "                    activation='relu'))\n",
    "    model.add(Dense(1, \n",
    "                    init='normal'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn = wider_model, \n",
    "                                         nb_epoch=100, \n",
    "                                         batch_size=5, \n",
    "                                         verbose=0)))\n",
    "\n",
    "# pipeline the estimators\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "# k-fold split\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, \n",
    "                          X, \n",
    "                          Y, \n",
    "                          cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

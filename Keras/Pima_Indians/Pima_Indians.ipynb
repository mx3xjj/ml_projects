{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: Create model to predict onset of Diabetes amongst Pima Indians #\n",
    "\n",
    "We will be using the Pima Indians dataset which records the onset of Diabetes within 5 years.\n",
    " \n",
    "* Number of Instances: 768\n",
    "* Number of Attributes: 8 plus class \n",
    "*  For Each Attribute: (all numeric-valued)\n",
    "       1. Number of times pregnant\n",
    "       2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "       3. Diastolic blood pressure (mm Hg)\n",
    "       4. Triceps skin fold thickness (mm)\n",
    "       5. 2-Hour serum insulin (mu U/ml)\n",
    "       6. Body mass index (weight in kg/(height in m)^2)\n",
    "       7. Diabetes pedigree function\n",
    "       8. Age (years)\n",
    "       9. Class variable (0: no diabetes or 1: diabetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check backend of Keras configuration #\n",
    "\n",
    "`\n",
    "Adarshs-MacBook-Pro:Github adarshnair$ cd ~/.keras\n",
    "Adarshs-MacBook-Pro:.keras adarshnair$ ls\n",
    "keras.json\n",
    "Adarshs-MacBook-Pro:.keras adarshnair$ cat keras.json\n",
    "{\n",
    "    \"image_dim_ordering\": \"tf\", \n",
    "    \"epsilon\": 1e-07, \n",
    "    \"floatx\": \"float32\", \n",
    "    \"backend\": \"tensorflow\"\n",
    "}\n",
    "Adarshs-MacBook-Pro:.keras adarshnair$ `\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Step 1: Load dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Create your first MLP in Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split data and define model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Fully connected layers are defined using the Dense class. \n",
    "'''\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "# features\n",
    "X = dataset[:, 0:8]\n",
    "# target\n",
    "Y = dataset[:, 8]\n",
    "\n",
    "# create Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer - takes 8 input features\n",
    "model.add(Dense(12, # number of neurons\n",
    "                input_dim = 8, # number of input features\n",
    "                init='uniform', # initialize network weights to random number generated from a uniform distribution\n",
    "                activation='relu'))\n",
    "\n",
    "# Hidden layer - takes 8 input features\n",
    "model.add(Dense(8, \n",
    "                init='uniform', \n",
    "                activation='relu'))\n",
    "\n",
    "# Output layer - \n",
    "model.add(Dense(1, # 1 neuron to give output\n",
    "                init='uniform', \n",
    "                activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compile and train model ## \n",
    "\n",
    "* loss: to evaluate the weights\n",
    "* optimizer: to search through the different weights for the network and find the best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', # logarithmic loss function\n",
    "              optimizer='adam', # gradient descent optimizer\n",
    "              metrics=['accuracy']) # accuracy metric as it is binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic verification dataset ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "514/514 [==============================] - 0s - loss: 0.4923 - acc: 0.7646 - val_loss: 0.4361 - val_acc: 0.7913\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s - loss: 0.4801 - acc: 0.7549 - val_loss: 0.4499 - val_acc: 0.7913\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s - loss: 0.4780 - acc: 0.7665 - val_loss: 0.4419 - val_acc: 0.7795\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s - loss: 0.4702 - acc: 0.7529 - val_loss: 0.4574 - val_acc: 0.7874\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s - loss: 0.4823 - acc: 0.7724 - val_loss: 0.4764 - val_acc: 0.7677\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s - loss: 0.4826 - acc: 0.7782 - val_loss: 0.4745 - val_acc: 0.7756\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s - loss: 0.4804 - acc: 0.7704 - val_loss: 0.4607 - val_acc: 0.7756\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s - loss: 0.4928 - acc: 0.7568 - val_loss: 0.4534 - val_acc: 0.7874\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s - loss: 0.4734 - acc: 0.7704 - val_loss: 0.4562 - val_acc: 0.7795\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s - loss: 0.4682 - acc: 0.7782 - val_loss: 0.4929 - val_acc: 0.7677\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s - loss: 0.4814 - acc: 0.7685 - val_loss: 0.4791 - val_acc: 0.7638\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s - loss: 0.4785 - acc: 0.7588 - val_loss: 0.4806 - val_acc: 0.7717\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s - loss: 0.4736 - acc: 0.7568 - val_loss: 0.4582 - val_acc: 0.7874\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s - loss: 0.4688 - acc: 0.7724 - val_loss: 0.4655 - val_acc: 0.7913\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s - loss: 0.4726 - acc: 0.7685 - val_loss: 0.4503 - val_acc: 0.7953\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s - loss: 0.4723 - acc: 0.7821 - val_loss: 0.4584 - val_acc: 0.7835\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s - loss: 0.4712 - acc: 0.7724 - val_loss: 0.4630 - val_acc: 0.7874\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s - loss: 0.4833 - acc: 0.7490 - val_loss: 0.4588 - val_acc: 0.7953\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s - loss: 0.4780 - acc: 0.7588 - val_loss: 0.4538 - val_acc: 0.7795\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s - loss: 0.4652 - acc: 0.7743 - val_loss: 0.4665 - val_acc: 0.7874\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s - loss: 0.4721 - acc: 0.7646 - val_loss: 0.4657 - val_acc: 0.7913\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s - loss: 0.4680 - acc: 0.7821 - val_loss: 0.4581 - val_acc: 0.7913\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s - loss: 0.4677 - acc: 0.7685 - val_loss: 0.4517 - val_acc: 0.7756\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s - loss: 0.4739 - acc: 0.7685 - val_loss: 0.4665 - val_acc: 0.7795\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s - loss: 0.4789 - acc: 0.7821 - val_loss: 0.4759 - val_acc: 0.7756\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s - loss: 0.4770 - acc: 0.7626 - val_loss: 0.4755 - val_acc: 0.7677\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s - loss: 0.4712 - acc: 0.7763 - val_loss: 0.4711 - val_acc: 0.7835\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s - loss: 0.4949 - acc: 0.7607 - val_loss: 0.4558 - val_acc: 0.7756\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s - loss: 0.4704 - acc: 0.7646 - val_loss: 0.4538 - val_acc: 0.7874\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s - loss: 0.4683 - acc: 0.7685 - val_loss: 0.4578 - val_acc: 0.7835\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s - loss: 0.4735 - acc: 0.7724 - val_loss: 0.4783 - val_acc: 0.7677\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s - loss: 0.4773 - acc: 0.7802 - val_loss: 0.4552 - val_acc: 0.7835\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s - loss: 0.4687 - acc: 0.7821 - val_loss: 0.4614 - val_acc: 0.7913\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s - loss: 0.4633 - acc: 0.7743 - val_loss: 0.4501 - val_acc: 0.7835\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s - loss: 0.4629 - acc: 0.7918 - val_loss: 0.4609 - val_acc: 0.7874\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s - loss: 0.4744 - acc: 0.7840 - val_loss: 0.4567 - val_acc: 0.7835\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s - loss: 0.4603 - acc: 0.7743 - val_loss: 0.4612 - val_acc: 0.7874\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s - loss: 0.4657 - acc: 0.7704 - val_loss: 0.4702 - val_acc: 0.7717\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s - loss: 0.4680 - acc: 0.7704 - val_loss: 0.4652 - val_acc: 0.8031\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s - loss: 0.4603 - acc: 0.7704 - val_loss: 0.5884 - val_acc: 0.7126\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s - loss: 0.5099 - acc: 0.7432 - val_loss: 0.4613 - val_acc: 0.7913\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s - loss: 0.4683 - acc: 0.7743 - val_loss: 0.4608 - val_acc: 0.7795\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s - loss: 0.4663 - acc: 0.7685 - val_loss: 0.4648 - val_acc: 0.7795\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s - loss: 0.4809 - acc: 0.7490 - val_loss: 0.4733 - val_acc: 0.7913\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s - loss: 0.4633 - acc: 0.7704 - val_loss: 0.4694 - val_acc: 0.7756\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s - loss: 0.4632 - acc: 0.7724 - val_loss: 0.4604 - val_acc: 0.7913\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s - loss: 0.4639 - acc: 0.7743 - val_loss: 0.4660 - val_acc: 0.7953\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s - loss: 0.4663 - acc: 0.7724 - val_loss: 0.4643 - val_acc: 0.7677\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s - loss: 0.4622 - acc: 0.7568 - val_loss: 0.4564 - val_acc: 0.7913\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s - loss: 0.4621 - acc: 0.7704 - val_loss: 0.4840 - val_acc: 0.7480\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s - loss: 0.4604 - acc: 0.7763 - val_loss: 0.4738 - val_acc: 0.7638\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s - loss: 0.4704 - acc: 0.7743 - val_loss: 0.4652 - val_acc: 0.7795\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s - loss: 0.4623 - acc: 0.7802 - val_loss: 0.4606 - val_acc: 0.7874\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s - loss: 0.4602 - acc: 0.7704 - val_loss: 0.4943 - val_acc: 0.7677\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s - loss: 0.4659 - acc: 0.7821 - val_loss: 0.4769 - val_acc: 0.7717\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s - loss: 0.4574 - acc: 0.7763 - val_loss: 0.4794 - val_acc: 0.7795\n",
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s - loss: 0.4672 - acc: 0.7704 - val_loss: 0.4753 - val_acc: 0.7677\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s - loss: 0.4626 - acc: 0.7860 - val_loss: 0.4591 - val_acc: 0.7677\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s - loss: 0.4561 - acc: 0.7743 - val_loss: 0.4622 - val_acc: 0.7874\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s - loss: 0.4581 - acc: 0.7821 - val_loss: 0.4575 - val_acc: 0.7677\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s - loss: 0.4621 - acc: 0.7821 - val_loss: 0.4556 - val_acc: 0.7717\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s - loss: 0.4672 - acc: 0.7626 - val_loss: 0.4658 - val_acc: 0.7835\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s - loss: 0.4719 - acc: 0.7763 - val_loss: 0.4683 - val_acc: 0.7677\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s - loss: 0.4691 - acc: 0.7763 - val_loss: 0.4880 - val_acc: 0.7677\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s - loss: 0.4834 - acc: 0.7685 - val_loss: 0.5224 - val_acc: 0.7283\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s - loss: 0.4971 - acc: 0.7471 - val_loss: 0.4593 - val_acc: 0.7953\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s - loss: 0.4668 - acc: 0.7743 - val_loss: 0.5117 - val_acc: 0.7638\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s - loss: 0.4816 - acc: 0.7490 - val_loss: 0.4617 - val_acc: 0.7717\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s - loss: 0.4580 - acc: 0.7743 - val_loss: 0.4683 - val_acc: 0.7795\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s - loss: 0.4583 - acc: 0.7743 - val_loss: 0.4690 - val_acc: 0.7598\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s - loss: 0.4510 - acc: 0.7704 - val_loss: 0.4712 - val_acc: 0.7717\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s - loss: 0.4619 - acc: 0.7782 - val_loss: 0.4755 - val_acc: 0.7795\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s - loss: 0.4540 - acc: 0.7918 - val_loss: 0.4689 - val_acc: 0.7795\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s - loss: 0.4682 - acc: 0.7704 - val_loss: 0.4621 - val_acc: 0.7677\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s - loss: 0.4582 - acc: 0.7782 - val_loss: 0.4684 - val_acc: 0.7835\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s - loss: 0.4605 - acc: 0.7704 - val_loss: 0.4552 - val_acc: 0.7795\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s - loss: 0.4601 - acc: 0.7704 - val_loss: 0.4587 - val_acc: 0.7756\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s - loss: 0.4714 - acc: 0.7763 - val_loss: 0.4639 - val_acc: 0.7598\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s - loss: 0.4603 - acc: 0.7918 - val_loss: 0.4795 - val_acc: 0.7756\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s - loss: 0.4616 - acc: 0.7685 - val_loss: 0.4654 - val_acc: 0.7795\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s - loss: 0.4584 - acc: 0.7840 - val_loss: 0.4740 - val_acc: 0.7638\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s - loss: 0.4685 - acc: 0.7782 - val_loss: 0.4952 - val_acc: 0.7520\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s - loss: 0.4662 - acc: 0.7899 - val_loss: 0.4633 - val_acc: 0.7677\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s - loss: 0.4525 - acc: 0.8016 - val_loss: 0.4635 - val_acc: 0.7795\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s - loss: 0.4610 - acc: 0.7899 - val_loss: 0.5062 - val_acc: 0.7913\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s - loss: 0.4645 - acc: 0.7782 - val_loss: 0.4534 - val_acc: 0.7677\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s - loss: 0.4630 - acc: 0.7724 - val_loss: 0.4729 - val_acc: 0.7795\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s - loss: 0.4663 - acc: 0.7724 - val_loss: 0.4621 - val_acc: 0.7756\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s - loss: 0.4540 - acc: 0.7763 - val_loss: 0.4926 - val_acc: 0.7913\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s - loss: 0.4582 - acc: 0.7899 - val_loss: 0.4598 - val_acc: 0.7717\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s - loss: 0.4494 - acc: 0.7938 - val_loss: 0.5424 - val_acc: 0.7402\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s - loss: 0.4602 - acc: 0.7918 - val_loss: 0.4563 - val_acc: 0.7756\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s - loss: 0.4492 - acc: 0.7938 - val_loss: 0.4565 - val_acc: 0.7717\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s - loss: 0.4553 - acc: 0.7782 - val_loss: 0.4812 - val_acc: 0.7717\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s - loss: 0.4576 - acc: 0.7704 - val_loss: 0.4570 - val_acc: 0.7717\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s - loss: 0.4658 - acc: 0.7724 - val_loss: 0.4690 - val_acc: 0.7874\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s - loss: 0.4551 - acc: 0.7782 - val_loss: 0.4539 - val_acc: 0.7874\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s - loss: 0.4502 - acc: 0.7763 - val_loss: 0.4852 - val_acc: 0.7913\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s - loss: 0.4490 - acc: 0.7763 - val_loss: 0.4713 - val_acc: 0.7717\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s - loss: 0.4608 - acc: 0.7821 - val_loss: 0.4725 - val_acc: 0.7717\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s - loss: 0.4517 - acc: 0.7899 - val_loss: 0.4704 - val_acc: 0.7795\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s - loss: 0.4487 - acc: 0.7743 - val_loss: 0.4673 - val_acc: 0.7677\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s - loss: 0.4481 - acc: 0.7938 - val_loss: 0.4776 - val_acc: 0.7953\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s - loss: 0.4536 - acc: 0.7918 - val_loss: 0.4766 - val_acc: 0.7756\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s - loss: 0.4692 - acc: 0.7977 - val_loss: 0.4824 - val_acc: 0.7677\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s - loss: 0.4631 - acc: 0.7782 - val_loss: 0.4911 - val_acc: 0.7835\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s - loss: 0.4588 - acc: 0.7821 - val_loss: 0.4707 - val_acc: 0.7717\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s - loss: 0.4590 - acc: 0.7626 - val_loss: 0.4513 - val_acc: 0.7795\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s - loss: 0.4577 - acc: 0.7743 - val_loss: 0.4649 - val_acc: 0.7756\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s - loss: 0.4486 - acc: 0.7802 - val_loss: 0.4941 - val_acc: 0.7677\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s - loss: 0.4528 - acc: 0.7763 - val_loss: 0.4625 - val_acc: 0.7677\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s - loss: 0.4474 - acc: 0.7918 - val_loss: 0.4798 - val_acc: 0.7717\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s - loss: 0.4407 - acc: 0.7802 - val_loss: 0.4609 - val_acc: 0.7638\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s - loss: 0.4659 - acc: 0.7899 - val_loss: 0.4788 - val_acc: 0.7717\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s - loss: 0.4505 - acc: 0.7899 - val_loss: 0.4792 - val_acc: 0.7598\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s - loss: 0.4584 - acc: 0.7840 - val_loss: 0.4755 - val_acc: 0.7677\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s - loss: 0.4484 - acc: 0.8016 - val_loss: 0.4689 - val_acc: 0.7717\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s - loss: 0.4622 - acc: 0.7802 - val_loss: 0.4693 - val_acc: 0.7638\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s - loss: 0.4696 - acc: 0.7743 - val_loss: 0.4572 - val_acc: 0.7874\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s - loss: 0.4456 - acc: 0.7840 - val_loss: 0.4636 - val_acc: 0.7835\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s - loss: 0.4453 - acc: 0.7802 - val_loss: 0.4853 - val_acc: 0.7677\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s - loss: 0.4566 - acc: 0.7821 - val_loss: 0.4573 - val_acc: 0.7677\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s - loss: 0.4487 - acc: 0.7860 - val_loss: 0.4541 - val_acc: 0.7677\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s - loss: 0.4467 - acc: 0.7840 - val_loss: 0.4598 - val_acc: 0.7874\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s - loss: 0.4556 - acc: 0.7724 - val_loss: 0.4536 - val_acc: 0.7717\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s - loss: 0.4660 - acc: 0.7724 - val_loss: 0.5426 - val_acc: 0.7638\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s - loss: 0.4517 - acc: 0.7840 - val_loss: 0.4555 - val_acc: 0.7795\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s - loss: 0.4614 - acc: 0.7763 - val_loss: 0.4587 - val_acc: 0.7677\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s - loss: 0.4637 - acc: 0.7802 - val_loss: 0.4807 - val_acc: 0.7756\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s - loss: 0.4459 - acc: 0.7899 - val_loss: 0.4665 - val_acc: 0.7717\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s - loss: 0.4440 - acc: 0.7957 - val_loss: 0.5469 - val_acc: 0.7598\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s - loss: 0.4527 - acc: 0.7840 - val_loss: 0.4780 - val_acc: 0.7638\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s - loss: 0.4528 - acc: 0.7879 - val_loss: 0.4539 - val_acc: 0.7795\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s - loss: 0.4657 - acc: 0.7685 - val_loss: 0.4613 - val_acc: 0.7795\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s - loss: 0.4448 - acc: 0.7977 - val_loss: 0.4692 - val_acc: 0.7677\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s - loss: 0.4608 - acc: 0.7782 - val_loss: 0.4719 - val_acc: 0.7677\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s - loss: 0.4593 - acc: 0.7879 - val_loss: 0.4638 - val_acc: 0.7795\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s - loss: 0.4463 - acc: 0.7938 - val_loss: 0.4957 - val_acc: 0.7520\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s - loss: 0.4590 - acc: 0.7840 - val_loss: 0.4906 - val_acc: 0.7677\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s - loss: 0.4577 - acc: 0.7763 - val_loss: 0.4905 - val_acc: 0.7835\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s - loss: 0.4586 - acc: 0.7704 - val_loss: 0.4756 - val_acc: 0.7795\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s - loss: 0.4475 - acc: 0.7957 - val_loss: 0.4761 - val_acc: 0.7677\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s - loss: 0.4446 - acc: 0.7860 - val_loss: 0.4820 - val_acc: 0.7756\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s - loss: 0.4549 - acc: 0.7879 - val_loss: 0.4826 - val_acc: 0.7598\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s - loss: 0.4446 - acc: 0.7860 - val_loss: 0.4886 - val_acc: 0.7598\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s - loss: 0.4485 - acc: 0.7782 - val_loss: 0.4936 - val_acc: 0.7795\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s - loss: 0.4481 - acc: 0.7763 - val_loss: 0.4583 - val_acc: 0.7835\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s - loss: 0.4420 - acc: 0.7802 - val_loss: 0.4750 - val_acc: 0.7795\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s - loss: 0.4481 - acc: 0.7918 - val_loss: 0.4655 - val_acc: 0.7795\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s - loss: 0.4469 - acc: 0.7840 - val_loss: 0.4650 - val_acc: 0.7559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10420c9d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Fit the model using an automatic verification dataset\n",
    "'''\n",
    "model.fit(X, # features\n",
    "          Y, # target\n",
    "          validation_split = 0.33,\n",
    "          nb_epoch=150, # number of iterations\n",
    "          batch_size=10) # number of instances evaluated before a weight update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual verification dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Fit the model using a manual verification dataset\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=seed)\n",
    "model.fit(X_train, # features\n",
    "          y_train, # target\n",
    "          validation_data=(X_test,y_test),\n",
    "          nb_epoch=150, # number of iterations\n",
    "          batch_size=10) # number of instances evaluated before a weight update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified k-fold cross validation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 71.43%\n",
      "acc: 71.43%\n",
      "acc: 75.32%\n",
      "acc: 80.52%\n",
      "acc: 79.22%\n",
      "acc: 75.32%\n",
      "acc: 75.32%\n",
      "acc: 74.03%\n",
      "acc: 75.00%\n",
      "acc: 73.68%\n",
      "75.13% (+/- 2.77%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Stratified split\n",
    "kfold = StratifiedKFold(n_splits=10, \n",
    "                        shuffle=True, \n",
    "                        random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, \n",
    "                    input_dim=8, \n",
    "                    init='uniform', \n",
    "                    activation='relu'))\n",
    "    model.add(Dense(8, \n",
    "                    init='uniform', \n",
    "                    activation='relu'))\n",
    "    model.add(Dense(1, \n",
    "                    init='uniform', \n",
    "                    activation='sigmoid'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X[train], Y[train], nb_epoch=150, batch_size=10, verbose=0)\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Performance evaluation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/768 [===========================>..] - ETA: 0sacc: 77.08%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing model using KerasClassifier ##\n",
    "\n",
    "* KerasClassifier\n",
    "* cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742139439747\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "\tmodel.add(Dense(12, \n",
    "                    input_dim=8, \n",
    "                    init='uniform', \n",
    "                    activation='relu'))\n",
    "    # Hidden layer\n",
    "\tmodel.add(Dense(8, \n",
    "                    init='uniform', \n",
    "                    activation='relu'))\n",
    "    \n",
    "    # Output layer\n",
    "\tmodel.add(Dense(1, \n",
    "                    init='uniform', \n",
    "                    activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", \n",
    "                        delimiter=\",\")\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn = create_model, \n",
    "                        nb_epoch=150, \n",
    "                        batch_size=10, \n",
    "                        verbose=0)\n",
    "\n",
    "\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits = 10, \n",
    "                        shuffle = True, \n",
    "                        random_state = seed)\n",
    "\n",
    "# cross validated score\n",
    "results = cross_val_score(model, \n",
    "                          X, \n",
    "                          Y, \n",
    "                          cv = kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implementing model using Grid Search ##\n",
    "\n",
    "Grid search is used to evaluate different configurations for the NN model and report the combination that provides the best estimated performance. \n",
    "\n",
    "* Optimizers: searching for different weight values\n",
    "* Initializers: preparing for network weights using different schemes\n",
    "* Number of epochs: for training the model to different number of exposures to the training set\n",
    "* Batches: varying the number of samples before weight updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset with grid search via sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='rmsprop', \n",
    "                 init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, \n",
    "                    input_dim=8, \n",
    "                    init=init, \n",
    "                    activation='relu'))\n",
    "    model.add(Dense(8, \n",
    "                    init=init, \n",
    "                    activation='relu'))\n",
    "    model.add(Dense(1, \n",
    "                    init=init, \n",
    "                    activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# Load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", \n",
    "                        delimiter=\",\")\n",
    "\n",
    "# Split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "# Create model\n",
    "model = KerasClassifier(build_fn = create_model, \n",
    "                        verbose=0)\n",
    "'''\n",
    "Grid Seach part of the model.\n",
    "'''\n",
    "# Grid search optimizers, initializations, epochs, batch sizes. \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = numpy.array([50, 100, 150])\n",
    "batches = numpy.array([5, 10, 20])\n",
    "\n",
    "# Parameter grid dictionary\n",
    "param_grid = dict(optimizer = optimizers, \n",
    "                  nb_epoch = epochs, \n",
    "                  batch_size = batches, \n",
    "                  init = init)\n",
    "\n",
    "# Grid search CV object with the estimator set to the KerasClassifier and parameter grid dictionary to iterate over\n",
    "grid = GridSearchCV(estimator = model, \n",
    "                    param_grid = param_grid)\n",
    "\n",
    "# Fit the model using the GridSearchCV object.\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Compute average scores\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
